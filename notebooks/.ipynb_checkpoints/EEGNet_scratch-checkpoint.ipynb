{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "from SciServer import CasJobs\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "#BELOW is necessary since we are not currently running from project directory\n",
    "#since we need to import libs from parent dir, need to add parent dir to path\n",
    "project_path = '/home/idies/workspace/Storage/ncarey/persistent/PULSD/PsychoPy-pylsl-RSVP/'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import importlib\n",
    "EEGModels = importlib.import_module(\"arl-eegmodels.EEGModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER:     (2) 'image_data_format' = 'channels_first' in keras.json config\n",
    "# If you get a negative dimension error or whatever, ensure the above and restart container\n",
    "\n",
    "\n",
    "model = EEGModels.EEGNet(nb_classes = 2, Chans=16, Samples=128)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=93856\n",
      "    Range : 0 ... 93855 =      0.000 ...   183.311 secs\n",
      "Ready.\n",
      "<RawArray  |  None, n_channels x n_times : 16 x 93856 (183.3 sec), ~11.5 MB, data loaded>\n"
     ]
    }
   ],
   "source": [
    "#Data shape = (trials, kernels, channels, samples), which for the \n",
    "#        input layer, will be (trials, 1, channels, samples). \n",
    "\n",
    "#Lets get this data\n",
    "session_ID=4\n",
    "context=\"MyDB\"\n",
    "\n",
    "channel_names = ['F3', 'Fz', 'F4', 'T7', 'C3', 'Cz', 'C4', 'T8', 'Cp3', 'Cp4', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "channel_types = ['eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg']\n",
    "sfreq = 512\n",
    "montage = 'standard_1005'\n",
    "info = mne.create_info(channel_names, sfreq, channel_types, montage)\n",
    "info['description'] = 'EEGNet test'\n",
    "\n",
    "raw_query = \"select * from session_eeg where session_ID = {0} order by timestamp\".format(session_ID)\n",
    "raw_df = CasJobs.executeQuery(sql=raw_query, context=context)\n",
    "\n",
    "raw_data = []\n",
    "for index in range(len(channel_names)):\n",
    "    raw_data.append(raw_df[channel_names[index]].values)\n",
    "\n",
    "custom_raw = mne.io.RawArray(raw_data, info)\n",
    "print(custom_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do this query to get the data reading index at which the stims appear.  IE, instead of \n",
    "# saying stim X was presented at time Y (as it is in the raw data), we want to \n",
    "#say stim X appeared at data reading index Z\n",
    "stim_index_query = '''\n",
    "with stim_timestamps_index(index_value, timestamp) as (\n",
    "select count(*), stim_timestamps.timestamp from session_eeg, stim_timestamps \n",
    "where session_eeg.session_ID = {0} and stim_timestamps.session_ID = {0} and session_eeg.timestamp < stim_timestamps.timestamp \n",
    "group by stim_timestamps.timestamp\n",
    ")\n",
    "\n",
    "select stim_timestamps_index.index_value, stim_timestamps.stim_ID from stim_timestamps_index, stim_timestamps \n",
    "where stim_timestamps.session_ID = {0} and stim_timestamps.timestamp = stim_timestamps_index.timestamp\n",
    "  order by stim_timestamps_index.index_value\n",
    "'''.format(session_ID)\n",
    "\n",
    "stim_index_df = CasJobs.executeQuery(sql=stim_index_query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ind = stim_index_df['index_value'].values\n",
    "stim_ID = stim_index_df['stim_ID'].values\n",
    "\n",
    "events = []\n",
    "for i in range(len(stim_ind)):\n",
    "    events.append([stim_ind[i]+1, 0, stim_ID[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "event_id = dict(t_04=0, t_03=1, t_02=2, t_01=3, d_10=4, d_09=5, d_08=6, d_07=7, d_06=8, d_05=9, d_04=10, d_03=11, d_02=12, d_01=13)\n",
    "epochs = mne.Epochs(raw=custom_raw, events=events, event_id=event_id, tmin=0, tmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 32 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 368 events and 513 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#Now we load the epochs into their respective target and distractor arrays of epochs\n",
    "# More importantly, we downsample to 128Hz, which is the input sampling rate EEGNet is setup for\n",
    "\n",
    "t_epochs = epochs['t_01', 't_02', 't_03', 't_04']\n",
    "t_epochs.load_data()\n",
    "t_epochs_resampled = t_epochs.copy().resample(128, npad='auto')\n",
    "\n",
    "\n",
    "d_epochs = epochs['d_01', 'd_02', 'd_03', 'd_04', 'd_05', 'd_06', 'd_07', 'd_08', 'd_09', 'd_10']\n",
    "d_epochs.load_data()\n",
    "d_epochs_resampled = d_epochs.copy().resample(128, npad='auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = t_epochs_resampled.get_data()  #32 epochs of 16 channels x 128 readings\n",
    "distract_data = d_epochs_resampled.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp0 = []\n",
    "tmp = []\n",
    "tmp1 = [[target_data[0]]]\n",
    "tmp2 = [[distract_data[0]]]\n",
    "\n",
    "tmp0.append(tmp2)\n",
    "#tmp0.append(tmp1)\n",
    "\n",
    "result = np.array([1,0])\n",
    "result = np.append(result, [0,1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected softmax to have shape (2,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-89babbd8eac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    905\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected softmax to have shape (2,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "fitted = model.fit(x=tmp0, y=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
