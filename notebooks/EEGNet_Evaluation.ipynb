{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciServer import CasJobs, Files, Authentication\n",
    "import sys\n",
    "import os.path\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "import mne\n",
    "from sklearn.utils import shuffle, class_weight #pip install --user sklearn\n",
    "\n",
    "#BELOW is necessary since we are not currently running from project directory\n",
    "#since we need to import libs from parent dir, need to add parent dir to path\n",
    "project_path = '/home/idies/workspace/Storage/ncarey/persistent/PULSD/PsychoPy-pylsl-RSVP/'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import importlib\n",
    "EEGModels = importlib.import_module(\"arl-eegmodels.EEGModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNEDataWrapper:\n",
    "    \n",
    "    def loadSession(self, session_ID):\n",
    "        print(\"Querying session {0} from CasJobs\".format(session_ID))\n",
    "        \n",
    "        info = mne.create_info(self.channel_names, self.recorded_sample_freq, self.channel_types, self.montage)\n",
    "        info['description'] = '16 channel EEG sessionID {0}'.format(session_ID)\n",
    "        \n",
    "        raw_query = \"select * from session_eeg where session_ID = {0} order by timestamp\".format(session_ID)\n",
    "        raw_df = CasJobs.executeQuery(sql=raw_query, context=self.casjobs_context)\n",
    "\n",
    "        raw_data = []\n",
    "        for index in range(len(self.channel_names)):\n",
    "            raw_data.append(raw_df[self.channel_names[index]].values)\n",
    "\n",
    "        custom_raw = mne.io.RawArray(raw_data, info)\n",
    "        \n",
    "        # we do this query to get the data reading index at which the stims appear.  IE, instead of \n",
    "        # saying stim X was presented at time Y (as it is in the raw data), we want to \n",
    "        # say stim X appeared at data reading index Z\n",
    "        stim_index_query = '''\n",
    "            with stim_timestamps_index(index_value, timestamp) as (\n",
    "            select count(*), stim_timestamps.timestamp from session_eeg, stim_timestamps \n",
    "            where session_eeg.session_ID = {0} and stim_timestamps.session_ID = {0} and session_eeg.timestamp < stim_timestamps.timestamp \n",
    "            group by stim_timestamps.timestamp\n",
    "            )\n",
    "\n",
    "            select stim_timestamps_index.index_value, stim_timestamps.stim_ID from stim_timestamps_index, stim_timestamps \n",
    "            where stim_timestamps.session_ID = {0} and stim_timestamps.timestamp = stim_timestamps_index.timestamp\n",
    "            order by stim_timestamps_index.index_value'''.format(session_ID)\n",
    "\n",
    "        stim_index_df = CasJobs.executeQuery(sql=stim_index_query, context=self.casjobs_context)\n",
    "\n",
    "        stim_ind = stim_index_df['index_value'].values\n",
    "        stim_ID = stim_index_df['stim_ID'].values\n",
    "\n",
    "        events = []\n",
    "        for i in range(len(stim_ind)):\n",
    "            events.append([stim_ind[i]+1, 0, stim_ID[i]])\n",
    "        \n",
    "        epochs = mne.Epochs(raw=custom_raw, events=events, event_id=self.event_id_dict, tmin=self.epoch_tmin, tmax=self.epoch_tmax)\n",
    "\n",
    "        # Now we load the epochs into their respective target and distractor arrays of epochs\n",
    "        # More importantly, we downsample to 128Hz, which is the input sampling rate EEGNet is setup for\n",
    "        \n",
    "        #Downsample to 128Hz\n",
    "        \n",
    "        epochs.load_data()\n",
    "        epochs_resampled = epochs.copy().resample(self.resample_rate, npad='auto')\n",
    "\n",
    "        target_epochs = epochs_resampled[self.target_epoch_names]\n",
    "        distract_epochs = epochs_resampled[self.distract_epoch_names]\n",
    "        \n",
    "        \n",
    "        self.sessions[session_ID] = [target_epochs, distract_epochs]\n",
    "        \n",
    "        #return target_epochs, distract_epochs \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # MNE-specific information\n",
    "        self.channel_names = ['F3', 'Fz', 'F4', 'T7', 'C3', 'Cz', 'C4', 'T8', 'Cp3', 'Cp4', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "        self.channel_types = ['eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg']\n",
    "        self.recorded_sample_freq = 512\n",
    "        self.montage = 'standard_1005'\n",
    "        self.target_epoch_names = ['t_01', 't_02', 't_03', 't_04']\n",
    "        self.distract_epoch_names = ['d_01', 'd_02', 'd_03', 'd_04', 'd_05', 'd_06', 'd_07', 'd_08', 'd_09', 'd_10']\n",
    "        self.event_id_dict = dict(t_04=0, t_03=1, t_02=2, t_01=3, d_10=4, d_09=5, d_08=6, d_07=7, d_06=8, d_05=9, d_04=10, d_03=11, d_02=12, d_01=13)\n",
    "        self.epoch_tmin = 0\n",
    "        self.epoch_tmax = 1\n",
    "        self.resample_rate = 128 #desired sample freq in Hz for EEGNet input \n",
    "        \n",
    "        self.casjobs_context = \"MyDB\"\n",
    "        \n",
    "        self.sessions = {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying session 2 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=81968\n",
      "    Range : 0 ... 81967 =      0.000 ...   160.092 secs\n",
      "Ready.\n",
      "320 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 320 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 3 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=93728\n",
      "    Range : 0 ... 93727 =      0.000 ...   183.061 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "MNEDataWrap = MNEDataWrapper()\n",
    "MNEDataWrap.loadSession(2)\n",
    "MNEDataWrap.loadSession(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNetWrapper:\n",
    "    \n",
    "    def loadSession(self, session_ID):\n",
    "        print(\"Querying session {0} from CasJobs\".format(session_ID))\n",
    "        \n",
    "        info = mne.create_info(self.channel_names, self.recorded_sample_freq, self.channel_types, self.montage)\n",
    "        info['description'] = '16 channel EEG sessionID {0}'.format(session_ID)\n",
    "        \n",
    "        raw_query = \"select * from session_eeg where session_ID = {0} order by timestamp\".format(session_ID)\n",
    "        raw_df = CasJobs.executeQuery(sql=raw_query, context=self.casjobs_context)\n",
    "\n",
    "        raw_data = []\n",
    "        for index in range(len(self.channel_names)):\n",
    "            raw_data.append(raw_df[self.channel_names[index]].values)\n",
    "\n",
    "        custom_raw = mne.io.RawArray(raw_data, info)\n",
    "        \n",
    "        # we do this query to get the data reading index at which the stims appear.  IE, instead of \n",
    "        # saying stim X was presented at time Y (as it is in the raw data), we want to \n",
    "        # say stim X appeared at data reading index Z\n",
    "        stim_index_query = '''\n",
    "            with stim_timestamps_index(index_value, timestamp) as (\n",
    "            select count(*), stim_timestamps.timestamp from session_eeg, stim_timestamps \n",
    "            where session_eeg.session_ID = {0} and stim_timestamps.session_ID = {0} and session_eeg.timestamp < stim_timestamps.timestamp \n",
    "            group by stim_timestamps.timestamp\n",
    "            )\n",
    "\n",
    "            select stim_timestamps_index.index_value, stim_timestamps.stim_ID from stim_timestamps_index, stim_timestamps \n",
    "            where stim_timestamps.session_ID = {0} and stim_timestamps.timestamp = stim_timestamps_index.timestamp\n",
    "            order by stim_timestamps_index.index_value'''.format(session_ID)\n",
    "\n",
    "        stim_index_df = CasJobs.executeQuery(sql=stim_index_query, context=self.casjobs_context)\n",
    "\n",
    "        stim_ind = stim_index_df['index_value'].values\n",
    "        stim_ID = stim_index_df['stim_ID'].values\n",
    "\n",
    "        events = []\n",
    "        for i in range(len(stim_ind)):\n",
    "            events.append([stim_ind[i]+1, 0, stim_ID[i]])\n",
    "        \n",
    "        epochs = mne.Epochs(raw=custom_raw, events=events, event_id=self.event_id_dict, tmin=self.epoch_tmin, tmax=self.epoch_tmax)\n",
    "\n",
    "        # Now we load the epochs into their respective target and distractor arrays of epochs\n",
    "        # More importantly, we downsample to 128Hz, which is the input sampling rate EEGNet is setup for\n",
    "        \n",
    "        #Downsample to 128Hz\n",
    "        \n",
    "        epochs.load_data()\n",
    "        epochs_resampled = epochs.copy().resample(self.resample_rate, npad='auto')\n",
    "\n",
    "        target_epochs = epochs_resampled[self.target_epoch_names]\n",
    "        distract_epochs = epochs_resampled[self.distract_epoch_names]\n",
    "        \n",
    "        return target_epochs, distract_epochs\n",
    "\n",
    "            \n",
    "    def loadTrainingData(self, session_ID):\n",
    "        target_epochs, distract_epochs = self.loadSession(session_ID)\n",
    "        \n",
    "        target_data = target_epochs.get_data()  # len(target_epochs) epochs of 16 channels x 128 readings\n",
    "        distract_data = distract_epochs.get_data()\n",
    "\n",
    "        \n",
    "        if len(self.training_data) == 0:\n",
    "            self.training_data = np.array(target_data[0], ndmin=4)\n",
    "            self.training_class = np.array([1,0], ndmin=2)\n",
    "        else:\n",
    "            self.training_data = np.append(self.training_data, np.array(target_data[0], ndmin=4), axis=0)\n",
    "            cur_class = np.array([1,0], ndmin=2)\n",
    "            self.training_class = np.append(self.training_class, cur_class, axis=0)\n",
    "\n",
    "        for i in range(1, len(target_data)):\n",
    "            cur_epoch = np.array(target_data[i], ndmin=4)\n",
    "            self.training_data = np.append(self.training_data, cur_epoch, axis=0)\n",
    "            cur_class = np.array([1,0], ndmin=2)\n",
    "            self.training_class = np.append(self.training_class, cur_class, axis=0)\n",
    "    \n",
    "        for i in range(0, len(distract_data)):\n",
    "            cur_epoch = np.array(distract_data[i], ndmin=4)\n",
    "            self.training_data = np.append(self.training_data, cur_epoch, axis=0)\n",
    "            cur_class = np.array([0,1], ndmin=2)\n",
    "            self.training_class = np.append(self.training_class, cur_class, axis=0)\n",
    "        \n",
    "    def loadEvaluationData(self, session_ID):\n",
    "        target_epochs, distract_epochs = self.loadSession(session_ID)\n",
    "        \n",
    "        target_data = target_epochs.get_data()  # len(target_epochs) epochs of 16 channels x 128 readings\n",
    "        distract_data = distract_epochs.get_data()\n",
    "\n",
    "        if len(self.eval_data) == 0:\n",
    "            self.eval_data = np.array(target_data[0], ndmin=4)\n",
    "            self.eval_class = np.array([1,0], ndmin=2)\n",
    "        else:\n",
    "            self.eval_data = np.append(self.eval_data, np.array(target_data[0], ndmin=4), axis=0)\n",
    "            cur_class = np.array([1,0], ndmin=2)\n",
    "            self.eval_class = np.append(self.eval_class, cur_class, axis=0)\n",
    "\n",
    "        for i in range(1, len(target_data)):\n",
    "            cur_epoch = np.array(target_data[i], ndmin=4)\n",
    "            self.eval_data = np.append(self.eval_data, cur_epoch, axis=0)\n",
    "            cur_class = np.array([1,0], ndmin=2)\n",
    "            self.eval_class = np.append(self.eval_class, cur_class, axis=0)\n",
    "    \n",
    "        for i in range(0, len(distract_data)):\n",
    "            cur_epoch = np.array(distract_data[i], ndmin=4)\n",
    "            self.eval_data = np.append(self.eval_data, cur_epoch, axis=0)\n",
    "            cur_class = np.array([0,1], ndmin=2)\n",
    "            self.eval_class = np.append(self.eval_class, cur_class, axis=0)\n",
    "            \n",
    "            \n",
    "    def fit(self, training_iterations):\n",
    "        self.fitted = self.model.fit(x=self.training_data, y=self.training_class, epochs=training_iterations) #validation_split=.2\n",
    "\n",
    "    def predict(self, data_to_predict):\n",
    "        print(self.model.predict(x=data_to_predict))\n",
    "        \n",
    "    def evaluate(self):\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        true_pos_count = 0\n",
    "        false_pos_count = 0\n",
    "        true_neg_count = 0\n",
    "        false_neg_count = 0\n",
    "        \n",
    "        for i in range(0, len(self.eval_data)):\n",
    "            #self.predict(np.array(self.eval_data[i], ndmin=4))\n",
    "            print(\"True Class: {0}\".format(self.eval_class[i]))\n",
    "            prediction = self.model.predict(x=np.array(self.eval_data[i], ndmin=4))\n",
    "            print(\"Prediction: {0}\".format(prediction))\n",
    "            if self.eval_class[i][0] == 1: #positive\n",
    "                pos_count = pos_count + 1\n",
    "                if prediction[0][0] > prediction[0][1]: #True Positive\n",
    "                    true_pos_count = true_pos_count + 1\n",
    "                else:\n",
    "                    false_neg_count = false_neg_count + 1\n",
    "            \n",
    "            else: #negative\n",
    "                neg_count = neg_count + 1\n",
    "                if prediction[0][0] < prediction[0][1]: #True Negative\n",
    "                    true_neg_count = true_neg_count + 1\n",
    "                else:\n",
    "                    false_pos_count = false_pos_count + 1\n",
    "            \n",
    "        result = '''True Positives: {0}, True Negatives: {1}, False Positives: {2}, False Negatives: {3}'''.format(true_pos_count, true_neg_count, false_pos_count, false_neg_count)\n",
    "        print(result)\n",
    "        \n",
    "            \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = EEGModels.EEGNet(nb_classes = 2, Chans=16, Samples=128)\n",
    "        self.model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "        \n",
    "        # MNE-specific information\n",
    "        self.channel_names = ['F3', 'Fz', 'F4', 'T7', 'C3', 'Cz', 'C4', 'T8', 'Cp3', 'Cp4', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "        self.channel_types = ['eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg']\n",
    "        self.recorded_sample_freq = 512\n",
    "        self.montage = 'standard_1005'\n",
    "        self.target_epoch_names = ['t_01', 't_02', 't_03', 't_04']\n",
    "        self.distract_epoch_names = ['d_01', 'd_02', 'd_03', 'd_04', 'd_05', 'd_06', 'd_07', 'd_08', 'd_09', 'd_10']\n",
    "        self.event_id_dict = dict(t_04=0, t_03=1, t_02=2, t_01=3, d_10=4, d_09=5, d_08=6, d_07=7, d_06=8, d_05=9, d_04=10, d_03=11, d_02=12, d_01=13)\n",
    "        self.epoch_tmin = 0\n",
    "        self.epoch_tmax = 1\n",
    "        self.resample_rate = 128 #desired sample freq in Hz for EEGNet input \n",
    "        \n",
    "        self.casjobs_context = \"MyDB\"\n",
    "                \n",
    "        self.training_data = []\n",
    "        self.training_class = []\n",
    "        \n",
    "        self.eval_data = []\n",
    "        self.eval_class = []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGNetWrap = EEGNetWrapper()\n",
    "for i in range(2, 19):  #Need to skip sessions 0, 1 as they are incomplete\n",
    "    EEGNetWrap.loadTrainingData(i)  \n",
    "    \n",
    "EEGNetWrap.fit(training_iterations=30)\n",
    "EEGNetWrap.loadEvaluationData(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGNetWrap.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ints = [y.argmax() for y in EEGNetWrap.training_class]\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(EEGNetWrap.training_class),\n",
    "                                                 y_ints)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
