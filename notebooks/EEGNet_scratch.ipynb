{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "from SciServer import CasJobs\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "#BELOW is necessary since we are not currently running from project directory\n",
    "#since we need to import libs from parent dir, need to add parent dir to path\n",
    "project_path = '/home/idies/workspace/Storage/ncarey/persistent/PULSD/PsychoPy-pylsl-RSVP/'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import importlib\n",
    "EEGModels = importlib.import_module(\"arl-eegmodels.EEGModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER:     (2) 'image_data_format' = 'channels_first' in keras.json config\n",
    "# If you get a negative dimension error or whatever, ensure the above and restart container\n",
    "\n",
    "\n",
    "model = EEGModels.EEGNet(nb_classes = 2, Chans=16, Samples=128)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=93856\n",
      "    Range : 0 ... 93855 =      0.000 ...   183.311 secs\n",
      "Ready.\n",
      "<RawArray  |  None, n_channels x n_times : 16 x 93856 (183.3 sec), ~11.5 MB, data loaded>\n"
     ]
    }
   ],
   "source": [
    "#Data shape = (trials, kernels, channels, samples), which for the \n",
    "#        input layer, will be (trials, 1, channels, samples). \n",
    "\n",
    "#Lets get this data\n",
    "session_ID=4\n",
    "context=\"MyDB\"\n",
    "\n",
    "channel_names = ['F3', 'Fz', 'F4', 'T7', 'C3', 'Cz', 'C4', 'T8', 'Cp3', 'Cp4', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "channel_types = ['eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg']\n",
    "sfreq = 512\n",
    "montage = 'standard_1005'\n",
    "info = mne.create_info(channel_names, sfreq, channel_types, montage)\n",
    "info['description'] = 'EEGNet test'\n",
    "\n",
    "raw_query = \"select * from session_eeg where session_ID = {0} order by timestamp\".format(session_ID)\n",
    "raw_df = CasJobs.executeQuery(sql=raw_query, context=context)\n",
    "\n",
    "raw_data = []\n",
    "for index in range(len(channel_names)):\n",
    "    raw_data.append(raw_df[channel_names[index]].values)\n",
    "\n",
    "custom_raw = mne.io.RawArray(raw_data, info)\n",
    "print(custom_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do this query to get the data reading index at which the stims appear.  IE, instead of \n",
    "# saying stim X was presented at time Y (as it is in the raw data), we want to \n",
    "#say stim X appeared at data reading index Z\n",
    "stim_index_query = '''\n",
    "with stim_timestamps_index(index_value, timestamp) as (\n",
    "select count(*), stim_timestamps.timestamp from session_eeg, stim_timestamps \n",
    "where session_eeg.session_ID = {0} and stim_timestamps.session_ID = {0} and session_eeg.timestamp < stim_timestamps.timestamp \n",
    "group by stim_timestamps.timestamp\n",
    ")\n",
    "\n",
    "select stim_timestamps_index.index_value, stim_timestamps.stim_ID from stim_timestamps_index, stim_timestamps \n",
    "where stim_timestamps.session_ID = {0} and stim_timestamps.timestamp = stim_timestamps_index.timestamp\n",
    "  order by stim_timestamps_index.index_value\n",
    "'''.format(session_ID)\n",
    "\n",
    "stim_index_df = CasJobs.executeQuery(sql=stim_index_query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ind = stim_index_df['index_value'].values\n",
    "stim_ID = stim_index_df['stim_ID'].values\n",
    "\n",
    "events = []\n",
    "for i in range(len(stim_ind)):\n",
    "    events.append([stim_ind[i]+1, 0, stim_ID[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "event_id = dict(t_04=0, t_03=1, t_02=2, t_01=3, d_10=4, d_09=5, d_08=6, d_07=7, d_06=8, d_05=9, d_04=10, d_03=11, d_02=12, d_01=13)\n",
    "epochs = mne.Epochs(raw=custom_raw, events=events, event_id=event_id, tmin=0, tmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 32 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 368 events and 513 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#Now we load the epochs into their respective target and distractor arrays of epochs\n",
    "# More importantly, we downsample to 128Hz, which is the input sampling rate EEGNet is setup for\n",
    "\n",
    "t_epochs = epochs['t_01', 't_02', 't_03', 't_04']\n",
    "t_epochs.load_data()\n",
    "t_epochs_resampled = t_epochs.copy().resample(128, npad='auto')\n",
    "\n",
    "\n",
    "d_epochs = epochs['d_01', 'd_02', 'd_03', 'd_04', 'd_05', 'd_06', 'd_07', 'd_08', 'd_09', 'd_10']\n",
    "d_epochs.load_data()\n",
    "d_epochs_resampled = d_epochs.copy().resample(128, npad='auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = t_epochs_resampled.get_data()  #32 epochs of 16 channels x 128 readings\n",
    "distract_data = d_epochs_resampled.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_epochs = np.array(target_data[0], ndmin=4)\n",
    "result = np.array([1,0], ndmin=2)\n",
    "\n",
    "for i in range(1, len(target_data)):\n",
    "    cur_epoch = np.array(target_data[i], ndmin=4)\n",
    "    input_epochs = np.append(input_epochs, cur_epoch, axis=0)\n",
    "    cur_result = np.array([1,0], ndmin=2)\n",
    "    result = np.append(result, cur_result, axis=0)\n",
    "#result = np.array([1,0])\n",
    "#result = np.append(result, [0,1], axis=0)\n",
    "result.shape\n",
    "#input_epochs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.8524\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 491us/step - loss: 0.7183\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 413us/step - loss: 0.6876\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 414us/step - loss: 0.7155\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 414us/step - loss: 0.6951\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 408us/step - loss: 0.6782\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 393us/step - loss: 0.6701\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 417us/step - loss: 0.6678\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 406us/step - loss: 0.6604\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 412us/step - loss: 0.6555\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 409us/step - loss: 0.6245\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 393us/step - loss: 0.6361\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 405us/step - loss: 0.6306\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 397us/step - loss: 0.6252\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 405us/step - loss: 0.6314\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 425us/step - loss: 0.6131\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 400us/step - loss: 0.6255\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 392us/step - loss: 0.6204\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 418us/step - loss: 0.5978\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 394us/step - loss: 0.5711\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 412us/step - loss: 0.6036\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 412us/step - loss: 0.5915\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 409us/step - loss: 0.5697\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 389us/step - loss: 0.5502\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 470us/step - loss: 0.5736\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 448us/step - loss: 0.5496\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 440us/step - loss: 0.5442\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 424us/step - loss: 0.5576\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 454us/step - loss: 0.5427\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 423us/step - loss: 0.5318\n"
     ]
    }
   ],
   "source": [
    "fitted = model.fit(x=input_epochs, y=result, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
