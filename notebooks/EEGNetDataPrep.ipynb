{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciServer import CasJobs, Files, Authentication\n",
    "import sys\n",
    "import os.path\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "import mne\n",
    "from sklearn.utils import shuffle, class_weight #pip install --user sklearn\n",
    "\n",
    "#BELOW is necessary since we are not currently running from project directory\n",
    "#since we need to import libs from parent dir, need to add parent dir to path\n",
    "project_path = '/home/idies/workspace/Storage/ncarey/persistent/PULSD/PsychoPy-pylsl-RSVP/'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNEDataWrapper:\n",
    "    \n",
    "    def loadSession(self, session_ID):\n",
    "        print(\"Querying session {0} from CasJobs\".format(session_ID))\n",
    "        \n",
    "        info = mne.create_info(self.channel_names, self.recorded_sample_freq, self.channel_types, self.montage)\n",
    "        info['description'] = '16 channel EEG sessionID {0}'.format(session_ID)\n",
    "        \n",
    "        raw_query = \"select * from session_eeg where session_ID = {0} order by timestamp\".format(session_ID)\n",
    "        raw_df = CasJobs.executeQuery(sql=raw_query, context=self.casjobs_context)\n",
    "\n",
    "        raw_data = []\n",
    "        for index in range(len(self.channel_names)):\n",
    "            raw_data.append(raw_df[self.channel_names[index]].values)\n",
    "\n",
    "        custom_raw = mne.io.RawArray(raw_data, info)\n",
    "        \n",
    "        # we do this query to get the data reading index at which the stims appear.  IE, instead of \n",
    "        # saying stim X was presented at time Y (as it is in the raw data), we want to \n",
    "        # say stim X appeared at data reading index Z\n",
    "        stim_index_query = '''\n",
    "            with stim_timestamps_index(index_value, timestamp) as (\n",
    "            select count(*), stim_timestamps.timestamp from session_eeg, stim_timestamps \n",
    "            where session_eeg.session_ID = {0} and stim_timestamps.session_ID = {0} and session_eeg.timestamp < stim_timestamps.timestamp \n",
    "            group by stim_timestamps.timestamp\n",
    "            )\n",
    "\n",
    "            select stim_timestamps_index.index_value, stim_timestamps.stim_ID from stim_timestamps_index, stim_timestamps \n",
    "            where stim_timestamps.session_ID = {0} and stim_timestamps.timestamp = stim_timestamps_index.timestamp\n",
    "            order by stim_timestamps_index.index_value'''.format(session_ID)\n",
    "\n",
    "        stim_index_df = CasJobs.executeQuery(sql=stim_index_query, context=self.casjobs_context)\n",
    "\n",
    "        stim_ind = stim_index_df['index_value'].values\n",
    "        stim_ID = stim_index_df['stim_ID'].values\n",
    "\n",
    "        events = []\n",
    "        for i in range(len(stim_ind)):\n",
    "            events.append([stim_ind[i]+1, 0, stim_ID[i]])\n",
    "        \n",
    "        epochs = mne.Epochs(raw=custom_raw, events=events, event_id=self.event_id_dict, tmin=self.epoch_tmin, tmax=self.epoch_tmax)\n",
    "\n",
    "        # Now we load the epochs into their respective target and distractor arrays of epochs\n",
    "        # More importantly, we downsample to 128Hz, which is the input sampling rate EEGNet is setup for\n",
    "        \n",
    "        #Downsample to 128Hz\n",
    "        \n",
    "        epochs.load_data()\n",
    "        epochs_resampled = epochs.copy().resample(self.resample_rate, npad='auto')\n",
    "\n",
    "        target_epochs = epochs_resampled[self.target_epoch_names]\n",
    "        distract_epochs = epochs_resampled[self.distract_epoch_names]\n",
    "        \n",
    "        \n",
    "        self.sessions[session_ID] = [target_epochs, distract_epochs]\n",
    "        \n",
    "        #return target_epochs, distract_epochs \n",
    "    \n",
    "    #converts from MNE Object to an array-format that can be consumed by EEGNet\n",
    "    def MNEtoEEGNetArray(self, session_ID):\n",
    "        target_epochs = self.sessions[session_ID][0]\n",
    "        distract_epochs = self.sessions[session_ID][1]\n",
    "        \n",
    "        target_data = target_epochs.get_data()  # len(target_epochs) epochs of 16 channels x 128 readings\n",
    "        distract_data = distract_epochs.get_data()\n",
    "\n",
    "        target_class = np.array([1,0], ndmin=2)\n",
    "        distract_class = np.array([0,1], ndmin=2)\n",
    "        \n",
    "        input_data = np.array(target_data[0], ndmin=4)\n",
    "        input_class = target_class\n",
    "\n",
    "        for i in range(1, len(target_data)):\n",
    "            cur_epoch = np.array(target_data[i], ndmin=4)\n",
    "            input_data = np.append(input_data, cur_epoch, axis=0)\n",
    "            input_class = np.append(input_class, target_class, axis=0)\n",
    "    \n",
    "        for i in range(0, len(distract_data)):\n",
    "            cur_epoch = np.array(distract_data[i], ndmin=4)\n",
    "            input_data = np.append(input_data, cur_epoch, axis=0)\n",
    "            input_class = np.append(input_class, distract_class, axis=0)\n",
    "            \n",
    "        return input_data, input_class\n",
    "        \n",
    "    \n",
    "    #trainingSessions and evaluationSessions are arrays of SessionIDs to include in the respective numpy array files\n",
    "    def saveToFile(self, trainingSessionsToSave, evaluationSessionsToSave):\n",
    "        training_data = []\n",
    "        training_class = []\n",
    "        eval_data = []\n",
    "        eval_class = []\n",
    "        \n",
    "        for session_ID in trainingSessionsToSave:\n",
    "            input_data, input_class = self.MNEtoEEGNetArray(session_ID)\n",
    "            if len(training_data) == 0:\n",
    "                training_data = input_data\n",
    "                training_class = input_class\n",
    "            else:\n",
    "                training_data = np.append(training_data, input_data, axis=0)\n",
    "                training_class = np.append(training_class, input_class, axis=0)\n",
    "            \n",
    "        for session_ID in evaluationSessionsToSave:\n",
    "            input_data, input_class = self.MNEtoEEGNetArray(session_ID)\n",
    "            if len(eval_data) == 0:\n",
    "                eval_data = input_data\n",
    "                eval_class = input_class\n",
    "            else:\n",
    "                eval_data = np.append(eval_data, input_data, axis=0)\n",
    "                eval_class = np.append(eval_class, input_class, axis=0)        \n",
    "        \n",
    "        np.save(\"training_data\", training_data)\n",
    "        np.save(\"training_class\", training_class)\n",
    "        np.save(\"eval_data\", eval_data)\n",
    "        np.save(\"eval_class\", eval_class)\n",
    "\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        # MNE-specific information\n",
    "        self.channel_names = ['F3', 'Fz', 'F4', 'T7', 'C3', 'Cz', 'C4', 'T8', 'Cp3', 'Cp4', 'P3', 'Pz', 'P4', 'PO7', 'PO8', 'Oz']\n",
    "        self.channel_types = ['eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg','eeg']\n",
    "        self.recorded_sample_freq = 512\n",
    "        self.montage = 'standard_1005'\n",
    "        self.target_epoch_names = ['t_01', 't_02', 't_03', 't_04']\n",
    "        self.distract_epoch_names = ['d_01', 'd_02', 'd_03', 'd_04', 'd_05', 'd_06', 'd_07', 'd_08', 'd_09', 'd_10']\n",
    "        self.event_id_dict = dict(t_04=0, t_03=1, t_02=2, t_01=3, d_10=4, d_09=5, d_08=6, d_07=7, d_06=8, d_05=9, d_04=10, d_03=11, d_02=12, d_01=13)\n",
    "        self.epoch_tmin = 0\n",
    "        self.epoch_tmax = 1\n",
    "        self.resample_rate = 128 #desired sample freq in Hz for EEGNet input \n",
    "        \n",
    "        self.casjobs_context = \"MyDB\"\n",
    "        \n",
    "        self.sessions = {}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying session 2 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=81968\n",
      "    Range : 0 ... 81967 =      0.000 ...   160.092 secs\n",
      "Ready.\n",
      "320 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 320 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 3 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=93728\n",
      "    Range : 0 ... 93727 =      0.000 ...   183.061 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 4 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=93856\n",
      "    Range : 0 ... 93855 =      0.000 ...   183.311 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 5 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=92752\n",
      "    Range : 0 ... 92751 =      0.000 ...   181.154 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 6 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=92784\n",
      "    Range : 0 ... 92783 =      0.000 ...   181.217 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 7 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=91968\n",
      "    Range : 0 ... 91967 =      0.000 ...   179.623 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 8 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=92240\n",
      "    Range : 0 ... 92239 =      0.000 ...   180.154 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 9 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=94224\n",
      "    Range : 0 ... 94223 =      0.000 ...   184.029 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 10 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=91408\n",
      "    Range : 0 ... 91407 =      0.000 ...   178.529 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 11 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=99296\n",
      "    Range : 0 ... 99295 =      0.000 ...   193.936 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 12 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=92912\n",
      "    Range : 0 ... 92911 =      0.000 ...   181.467 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 13 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=90512\n",
      "    Range : 0 ... 90511 =      0.000 ...   176.779 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 14 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=91056\n",
      "    Range : 0 ... 91055 =      0.000 ...   177.842 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 15 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=90384\n",
      "    Range : 0 ... 90383 =      0.000 ...   176.529 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 16 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=90912\n",
      "    Range : 0 ... 90911 =      0.000 ...   177.561 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 17 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=90880\n",
      "    Range : 0 ... 90879 =      0.000 ...   177.498 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 18 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=91040\n",
      "    Range : 0 ... 91039 =      0.000 ...   177.811 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n",
      "Querying session 19 from CasJobs\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=92672\n",
      "    Range : 0 ... 92671 =      0.000 ...   180.998 secs\n",
      "Ready.\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 400 events and 513 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "MNEDataWrap = MNEDataWrapper()\n",
    "for i in range(2,20):\n",
    "    MNEDataWrap.loadSession(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNEDataWrap.saveToFile([2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
